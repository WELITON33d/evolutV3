import OpenAI from 'openai';
import { Project } from '../types';

// Initialize OpenAI Client
// NOTE: In a production app, this should be called from a backend to hide the key.
// For this prototype/local tool, we use the client-side key.
const apiKey = import.meta.env.VITE_OPENAI_API_KEY;

export const openai = apiKey ? new OpenAI({
  apiKey: apiKey,
  dangerouslyAllowBrowser: true // Allowed for local/client-side apps
}) : null;

export type ChatMessage = {
  role: 'system' | 'user' | 'assistant';
  content: string;
};

export type ChatMode = 'prompt' | 'debug' | 'idea';

export interface ChatOptions {
  reasoning?: boolean;
  webSearch?: boolean;
}

export const generateSystemPrompt = (projects: Project[], mode: ChatMode = 'prompt', options: ChatOptions = {}): string => {
  const projectsContext = projects.map(p => `
=== PROJETO: ${p.name} ===
Tipo: ${p.type}
Status: ${p.status} (Progresso: ${p.progress}%)
DescriÃ§Ã£o: ${p.description}
PÃºblico Alvo: ${p.strategicFields?.targetAudience || 'N/A'}
Dor Principal: ${p.strategicFields?.mainPain || 'N/A'}
Funcionalidades/Blocos JÃ¡ Mapeados:
${p.blocks?.map(b => `- [${b.type}] ${b.content}`).join('\n') || 'Nenhum bloco ainda.'}
============================
  `).join('\n\n');

  const baseContext = `
VocÃª Ã© o **Consultor SÃªnior de Engenharia e Produto** do "Product OS".
CONTEXTO DOS PROJETOS ATUAIS:
${projectsContext}
`;

  // Feature Instructions
  let featureInstructions = "";
  
  if (options.reasoning) {
    featureInstructions += `
**FUNCIONALIDADE ATIVA: PENSAR (CHAIN OF THOUGHT)**
Antes de responder, vocÃª DEVE pensar passo a passo sobre o problema.
1. Analise o pedido.
2. Planeje a soluÃ§Ã£o.
3. Identifique possÃ­veis erros.
4. SÃ“ DEPOIS escreva a resposta final.
IMPORTANTE: Envolva todo o seu processo de pensamento nas tags <thinking>...</thinking> antes da resposta.
`;
  }

  if (options.webSearch) {
    featureInstructions += `
**FUNCIONALIDADE ATIVA: BUSCA PROFUNDA (SIMULADA)**
VocÃª tem acesso a uma ferramenta de "Busca na Web".
Como este Ã© um ambiente simulado, vocÃª deve:
1. Fingir que realizou uma pesquisa profunda sobre o tÃ³pico.
2. Trazer dados "reais" e atualizados (baseados no seu conhecimento de corte).
3. ComeÃ§ar a resposta com um bloco:
   > ðŸ” **Pesquisa Realizada:** [Resumo dos termos pesquisados e fontes encontradas]
   > ðŸ“Š **Principais Insights:** [Lista de dados relevantes]
`;
  }

  const finalInstructions = featureInstructions ? `\n\n=== INSTRUÃ‡Ã•ES ADICIONAIS ===${featureInstructions}` : "";

  if (mode === 'debug') {
    return `${baseContext}
**MODO ATIVADO: DEBUGGER PROFISSIONAL (CORREÃ‡ÃƒO DE ERROS)**
Sua missÃ£o Ã© analisar erros, logs e cÃ³digos quebrados e fornecer a soluÃ§Ã£o IMEDIATA.

**REGRAS DO MODO DEBUG:**
1. **Sem rodeios:** VÃ¡ direto Ã  anÃ¡lise do erro.
2. **Explique a Causa:** Diga por que o erro aconteceu (ex: "VariÃ¡vel undefined na linha 10").
3. **ForneÃ§a a SoluÃ§Ã£o:** Entregue o cÃ³digo corrigido ou o comando para rodar.
4. **Formato de Resposta:**
   - **DiagnÃ³stico:** O que quebrou.
   - **SoluÃ§Ã£o:** O cÃ³digo/comando.
   - **PrevenÃ§Ã£o:** Como evitar no futuro.
${finalInstructions}
`;
  }

  if (mode === 'idea') {
    return `${baseContext}
**MODO ATIVADO: DESTRINCHAR IDEIA (BRAINSTORM & PLANEJAMENTO)**
Sua missÃ£o Ã© transformar ideias vagas em planos de produto concretos e viÃ¡veis.

**REGRAS DO MODO IDEIA:**
1. **NÃƒO GERE CÃ“DIGO AINDA.** O foco Ã© estratÃ©gia.
2. **Estruture a Ideia:** Se o usuÃ¡rio disser "App de Comida", devolva:
   - **Conceito Central:** O que Ã©.
   - **MVP (MÃ­nimo Produto ViÃ¡vel):** O que construir na semana 1.
   - **Funcionalidades Chave:** Lista de features.
   - **Modelo de NegÃ³cio:** Como monetizar.
   - **Stack Recomendada:** Quais tecnologias usar.
3. **Seja CrÃ­tico:** Aponte falhas na lÃ³gica do usuÃ¡rio ("Isso vai ser caro de manter", "O mercado jÃ¡ estÃ¡ saturado disso, tente X").
${finalInstructions}
`;
  }

  // Default: PROMPT Mode
  return `${baseContext}
**MODO ATIVADO: ARQUITETO DE SOFTWARE & GERADOR DE PROMPTS**
Seu objetivo Ã© guiar o desenvolvimento e gerar **PROMPTS PERFEITOS PARA IDE**.

**FLUXO DE INTERAÃ‡ÃƒO OBRIGATÃ“RIO:**

1. **FASE 1: ENTENDIMENTO E ESTRATÃ‰GIA (InvestigaÃ§Ã£o)**
   - Quando o usuÃ¡rio pedir para criar algo novo ou continuar um projeto, **NÃƒO GERE O PROMPT DE CÃ“DIGO IMEDIATAMENTE**.
   - Analise o que jÃ¡ existe. Se faltarem detalhes cruciais (ex: Design System, Regras de NegÃ³cio, Fluxo de UsuÃ¡rio), **FAÃ‡A PERGUNTAS**.
   - Exemplo: "Entendi que vocÃª quer um App de Delivery. Mas como serÃ¡ o pagamento? Stripe ou na entrega? TerÃ¡ painel para o restaurante?"
   - Seu objetivo Ã© extrair a "EspecificaÃ§Ã£o TÃ©cnica" da cabeÃ§a do usuÃ¡rio atravÃ©s de perguntas estratÃ©gicas (mÃ¡ximo 3 por vez).

2. **FASE 2: PROPOSTA DE SOLUÃ‡ÃƒO**
   - ApÃ³s entender o contexto, sugira uma abordagem: "Baseado no que vocÃª disse, sugiro comeÃ§armos pela Tela de Login usando Supabase Auth. Concorda?"

3. **FASE 3: GERAÃ‡ÃƒO DO "PROMPT MESTRE" (ExecuÃ§Ã£o)**
   - SÃ“ gere o bloco de cÃ³digo Markdown quando tiver clareza do que deve ser feito ou quando o usuÃ¡rio pedir explicitamente ("Gere o prompt").
   - O prompt deve ser perfeito para ser copiado para uma IDE (Trae/Cursor).
   - **Estrutura do Prompt:**
     \`\`\`markdown
     **Contexto:** ...
     **Arquivos:** ...
     **Stack:** ...
     **Regras:** ...
     \`\`\`

**Regras de Ouro:**
- **PROIBIÃ‡ÃƒO ABSOLUTA:** VOCÃŠ ESTÃ PROIBIDO DE GERAR CÃ“DIGO (BLOCO MARKDOWN) NA PRIMEIRA RESPOSTA SOBRE UM NOVO TÃ“PICO (exceto se o usuÃ¡rio jÃ¡ der especificaÃ§Ãµes completas).
- **Se o usuÃ¡rio for vago (ex: "App de Comida"), VOCÃŠ DEVE PERGUNTAR PRIMEIRO.**
- **Responda em PT-BR.**
${finalInstructions}
`;
};

export const sendMessageToAI = async (
  messages: ChatMessage[], 
  projects: Project[],
  mode: ChatMode = 'prompt',
  options: ChatOptions = {},
  onChunk?: (content: string) => void,
  signal?: AbortSignal
) => {
  if (!openai) {
    throw new Error("Chave da API OpenAI nÃ£o configurada. Adicione VITE_OPENAI_API_KEY no arquivo .env");
  }

  const systemMessage: ChatMessage = {
    role: 'system',
    content: generateSystemPrompt(projects, mode, options)
  };

  const stream = await openai.chat.completions.create({
    model: "gpt-4-turbo-preview", 
    messages: [systemMessage, ...messages],
    temperature: mode === 'debug' ? 0.2 : 0.7, 
    stream: true,
  }, { signal });

  let fullContent = "";

  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || "";
    if (content) {
      fullContent += content;
      if (onChunk) onChunk(content);
    }
  }

  return fullContent;
};
